# 云台跟踪实验
在[视觉实验](/docs/Tutorial/2.3-Vision-Test.md)演示了如何控制机器人跟踪二维码，本章将讲解如何控制机器人的头部Xtion跟踪二维码。HandFree机器人的头部是由二自由度云台构成，Xtion置于云台上，可以进行俯仰和偏转运动。  
云台由两个模拟舵机组成，确保舵机已正确连接至主控。实现头部跟踪的过程与上一章节的过程类似。  
建议节点都在工控机上运行

## 机器人抽象节点
打开机器人抽象节点

```
roslaunch handsfree_hw handsfree_hw.launch
```

确保工控机及机器人底层连接正常,如果不能,请参考[常见问题及解答](/docs/FAQ/solution-of-handsfree-hw-error.md)进行解决。  

## 摄像头驱动节点
打开Xtion驱动节点，将发布一系列RGB图像数据和深度图像数据。

```
roslaunch handsfree_camera xtion.launch  
```

## 识别节点  
使用RGB图像数据进行二维码识别：

```
roslaunch handsfree_ar_tags ar_indiv_rgb_camera.launch  
```
运行结果大致如下所示：

```
ROS_MASTER_URI=http://Robot:11311

core service [/rosout] found
process[ar_track_alvar-1]: started with pid [10310]
[ WARN] [1517366973.387724985]: Command line arguments are deprecated. Consider using ROS parameters and remappings.
[ INFO] [1517366973.392963280]: Subscribing to info topic
[ INFO] [1517366973.460607649]: AR tracker reconfigured: ENABLED 10.00 6.60 0.08 0.05
[ INFO] [1517366974.469605297]: Subscribing to image topic

```
或者使用深度图像数据进行二维码识别：

```
roslaunch handsfree_ar_tags ar_indiv_depth_camera.launch  
```

上面两条命令二选一即可，它们都是使用开源的二维码识别库进行二维码的识别，`ar_indiv_rgb_camera.launch`和`ar_indiv_depth_camera.launch`的区别主要是订阅的话题不同，更多资料请参考[ar_track_alvar](http://wiki.ros.org/ar_track_alvar/)的WIKI。  

## 头部跟踪节点  
运行头部跟踪器。

```
rosrun handsfree_ar_tags head_tracker.py
```

将`/handsfree/handsfree_ar_tags/config/Markers_0_2.png`文件打印在纸上，将打印出的图案放置在Xtion摄像头前方，慢慢移动图案，机器人的头部将跟随二维码图案位置的移动而运动。  

